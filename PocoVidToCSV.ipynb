{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DoitDigital-lab/Calculadora/blob/main/PocoVidToCSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiJQWMnygAKc",
        "outputId": "38260102-dd1d-4cfc-c4ad-4def5c890263"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/full_path')\n",
        "sys.path.append('/content/drive/MyDrive/Pocovid/pocovidnet/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJOoRwyxgIUj"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from imutils import paths\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from pocovidnet import MODEL_FACTORY\n",
        "from pocovidnet.utils import Metrics\n",
        "from tensorflow.keras.models import Model\n",
        "import os\n",
        "from imutils import paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "BK7FYNEEgT_c"
      },
      "source": [
        "#@title Texto de t√≠tulo predeterminado\n",
        "def naive(name):\n",
        "\t# Suppress logging\n",
        "\ttf.get_logger().setLevel('ERROR')\n",
        "\t# Initialize hyperparameters\n",
        "\tDATA_DIR = \"/content/drive/MyDrive/Pocovid/data/cross_validation/\"\n",
        "\t#DATA_DIR = \"/content/drive/MyDrive/Pocovid/data/SuperC/\"\n",
        "\tMODEL_NAME = str(name)\n",
        "\tFOLD = \"4\"\n",
        "\tMODEL_DIR = os.path.join('models/', MODEL_NAME, f'fold_4')\n",
        "\tLR = 1e-4\n",
        "\tEPOCHS = 30\n",
        "\tBATCH_SIZE = 32\n",
        "\tMODEL_ID = \"vgg_base\"\n",
        "\tTRAINABLE_BASE_LAYERS = 1\n",
        "\tIMG_WIDTH, IMG_HEIGHT = 224, 224\n",
        "\tLOG_SOFTMAX = True\n",
        "\tHIDDEN_SIZE = 64\n",
        "\tfilter_types_applied = str(name)\n",
        "\tfilter_types_applied_string=str(name);\n",
        "\t# Check if model class exists\n",
        "\tif MODEL_ID not in MODEL_FACTORY.keys():\n",
        "\t  raise ValueError(\n",
        "\t\tf'Model {MODEL_ID} not implemented. Choose from {MODEL_FACTORY.keys()}'\n",
        "\t\t)\n",
        "\n",
        "\tif not os.path.exists(MODEL_DIR):\n",
        "\t\tos.makedirs(MODEL_DIR)\n",
        "\n",
        "\t# grab the list of images in our dataset directory, then initialize\n",
        "\t# the list of data (i.e., images) and class images\n",
        "\tprint('Loading images...')\n",
        "\timagePaths = list(paths.list_images(DATA_DIR))\n",
        "\tdata = []\n",
        "\tlabels = []\n",
        "\n",
        "\tprint(f'selected fold: {FOLD}')\n",
        "\n",
        "\ttrain_labels, test_labels = [], []\n",
        "\ttrain_data, test_data = [], []\n",
        "\t# test_files = []\n",
        "\n",
        "\t# loop over folds\n",
        "\tfor imagePath in imagePaths:\n",
        "\n",
        "\t\tpath_parts = imagePath.split(os.path.sep)\n",
        "\t\t#extract the split\n",
        "\t\ttrain_test = path_parts[-3][-1]\n",
        "\t\t# extract the class label from the filename\n",
        "\t\tlabel = path_parts[-2]\n",
        "\t\timage = cv2.imread(imagePath)\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\t\tfor filterType in filter_types_applied:\n",
        "\t\t\tif filterType == \"0\" :\n",
        "\t\t\t\timage = image\n",
        "\t\t\tif filterType == \"1\" :\n",
        "\t\t\t\tkernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "\t\t\t\timage = cv2.filter2D(image, -1, kernel)\n",
        "\t\t\tif filterType == \"2\" :\n",
        "\t\t\t\tksize = (3, 3)\n",
        "\t\t\t\timage = cv2.blur(image, ksize)\n",
        "\t\t\tif filterType == \"3\" :\n",
        "\t\t\t  image = cv2.medianBlur(image,3)\n",
        "\t\t\tif filterType == \"4\" :\n",
        "\t\t\t\timage = cv2.Laplacian(image,cv2.CV_8U)\n",
        "\t\t\tif filterType == \"5\" :\n",
        "\t\t\t\timage = cv2.Sobel(image,cv2.CV_8U,1,0,ksize=3)\n",
        "\t\t\tif filterType == \"6\" :\n",
        "\t\t\t\tR, G, B = cv2.split(image)\n",
        "\t\t\t\toutput1_R = cv2.equalizeHist(R)\n",
        "\t\t\t\toutput1_G = cv2.equalizeHist(G)\n",
        "\t\t\t\toutput1_B = cv2.equalizeHist(B)\n",
        "\t\t\t\timage = cv2.merge((output1_R, output1_G, output1_B))\n",
        "\n",
        "\n",
        "\n",
        "\t\timage = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\t\tif train_test == str(FOLD):\n",
        "\t\t\ttest_labels.append(label)\n",
        "\t\t\ttest_data.append(image)\n",
        "\t\t\t# test_files.append(path_parts[-1])\n",
        "\t\telse:\n",
        "\t\t\ttrain_labels.append(label)\n",
        "\t\t\ttrain_data.append(image)\n",
        "\n",
        "\t# Prepare data for model\n",
        "\tprint(\n",
        "\t\tf'\\nNumber of training samples: {len(train_labels)} \\n'\n",
        "\t\tf'Number of testing samples: {len(test_labels)}'\n",
        "\t)\n",
        "\n",
        "\tassert len(set(train_labels)) == len(set(test_labels)), (\n",
        "\t\t'Something went wrong. Some classes are only in train or test data.'\n",
        "\t)  # yapf: disable\n",
        "\n",
        "\t# convert the data and labels to NumPy arrays while scaling the pixel\n",
        "\t# intensities to the range [0, 255]\n",
        "\ttrain_data = np.array(train_data) / 255.0\n",
        "\ttest_data = np.array(test_data) / 255.0\n",
        "\ttrain_labels_text = np.array(train_labels)\n",
        "\ttest_labels_text = np.array(test_labels)\n",
        "\n",
        "\tnum_classes = len(set(train_labels))\n",
        "\n",
        "\t# perform one-hot encoding on the labels\n",
        "\tlb = LabelBinarizer()\n",
        "\tlb.fit(train_labels_text)\n",
        "\n",
        "\ttrain_labels = lb.transform(train_labels_text)\n",
        "\ttest_labels = lb.transform(test_labels_text)\n",
        "\n",
        "\tif num_classes == 2:\n",
        "\t\ttrain_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "\t\ttest_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "\ttrainX = train_data\n",
        "\ttrainY = train_labels\n",
        "\ttestX = test_data\n",
        "\ttestY = test_labels\n",
        "\tprint('Class mappings are:', lb.classes_)\n",
        "\n",
        "\n",
        "\ttrainAug = ImageDataGenerator(\n",
        "\t\trotation_range=10,\n",
        "\t\tfill_mode='nearest',\n",
        "\t\thorizontal_flip=True,\n",
        "\t\tvertical_flip=True,\n",
        "\t\twidth_shift_range=0.1,\n",
        "\t\theight_shift_range=0.1\n",
        "\t\n",
        "\t)\n",
        "\n",
        "\t# Load the VGG16 network\n",
        "\tprint('Compiling VGG16...')\n",
        "\tmodel = MODEL_FACTORY[MODEL_ID](\n",
        "\t\tinput_size=(IMG_WIDTH, IMG_HEIGHT, 3),\n",
        "\t\tnum_classes=num_classes,\n",
        "\t\ttrainable_layers=TRAINABLE_BASE_LAYERS,\n",
        "\t\tlog_softmax=LOG_SOFTMAX,\n",
        "\t\thidden_size=HIDDEN_SIZE\n",
        "\t)\n",
        "\n",
        "\tmetrics = Metrics((testX, testY), model)\n",
        "\n",
        "\t# compile model\n",
        "\tprint('Compiling model...')\n",
        "\topt = Adam(learning_rate=LR, decay=LR / EPOCHS)\n",
        "\tloss = (\n",
        "\t\ttf.keras.losses.CategoricalCrossentropy() if not LOG_SOFTMAX else (\n",
        "\t\t\tlambda labels, targets: tf.reduce_mean(\n",
        "\t\t\t\ttf.reduce_sum(\n",
        "\t\t\t\t\t-1 * tf.math.multiply(tf.cast(labels, tf.float32), targets),\n",
        "\t\t\t\t\taxis=1\n",
        "\t\t\t\t)\n",
        "\t\t\t)\n",
        "\t\t)\n",
        "\t)\n",
        "\n",
        "\n",
        "\tmodel.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "\tprint(f'Model has {model.count_params()} parameters')\n",
        "\tprint(f'Model summary {model.summary()}')\n",
        "\n",
        "\t# train the head of the network\n",
        "\tprint('Starting training model...')\n",
        "\tmodel.fit(trainAug.flow(x=trainX, y=trainY, batch_size=BATCH_SIZE),epochs=EPOCHS)\n",
        "\tprint('Done')\n",
        "\n",
        "\t#model_ = Model(inputs=model.input, outputs=model.get_layer(index=-5).output)\n",
        "#\tprint(model_.summary())\n",
        "\tcsv_data = []\n",
        "  \n",
        "  # if filter_types_applied == \"1\" :\n",
        "  #   print(\"blur filter aplicated\")\n",
        "  #   filter_types_applied_string += \"filter2D\"\n",
        "\tfor filterType in filter_types_applied:\n",
        "\t\tif filterType == \"0\" :\n",
        "\t\t\tfilter_types_applied_string += \"noFilter\"\n",
        "\t\tif filterType == \"1\" :\n",
        "\t\t\tprint(\"2d filter aplicated\")\n",
        "\t\t\tfilter_types_applied_string += \"filter2D\"\n",
        "\t\tif filterType == \"2\" :\n",
        "\t\t\tprint(\"blur filter aplicated\")\n",
        "\t\t\tfilter_types_applied_string += \"blur\"\n",
        "\t\tif filterType == \"3\" :\n",
        "\t\t\tprint(\"medianBlur filter aplicated\")\n",
        "\t\t\tfilter_types_applied_string += \"medianBlur\"\n",
        "\t\tif filterType == \"4\" :\n",
        "\t\t\tprint(\"Laplacian filter aplicated\")\n",
        "\t\t\tfilter_types_applied_string += \"Laplacian\"\n",
        "\t\tif filterType == \"5\" :\n",
        "\t\t\tprint(\"Sobel filter aplicated\")\n",
        "\t\t\tfilter_types_applied_string += \"Sobel\"\n",
        "\t\tif filterType == \"6\" :\n",
        "\t\t\tprint(\"equalizeHist filter aplicated\")\n",
        "\t\t\tfilter_types_applied_string += \"equalizeHist\"\n",
        "   \n",
        "\t\t\n",
        "\tfor imagePath in imagePaths:\n",
        "\t\timages=[]\n",
        "\t\tpath_parts = imagePath.split(os.path.sep)\n",
        "\t\ttrain_test = path_parts[-3][-1]\n",
        "\t\tlabel = path_parts[-2]\n",
        "\n",
        "\t\timage = cv2.imread(imagePath)\n",
        "\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "\n",
        "\t\tfor filterType in filter_types_applied:\n",
        "\t\t\tif filterType == \"0\" :\n",
        "\t\t\t\timage = image\n",
        "\t\t\tif filterType == \"1\" :\n",
        "\t\t\t\tkernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "\t\t\t\timage = cv2.filter2D(image, -1, kernel)\n",
        "\t\t\tif filterType == \"2\" :\n",
        "\t\t\t\tksize = (3, 3)\n",
        "\t\t\t\timage = cv2.blur(image, ksize)\n",
        "\t\t\tif filterType == \"3\" :\n",
        "\t\t\t\timage = cv2.medianBlur(image,3)\n",
        "\t\t\tif filterType == \"4\" :\n",
        "\t\t\t\timage = cv2.Laplacian(image,cv2.CV_8U)\n",
        "\t\t\tif filterType == \"5\" :\n",
        "\t\t\t\timage = cv2.Sobel(image,cv2.CV_8U,1,0,ksize=3)\n",
        "\t\t\tif filterType == \"6\" :\n",
        "\t\t\t\tR, G, B = cv2.split(image)\n",
        "\t\t\t\toutput1_R = cv2.equalizeHist(R)\n",
        "\t\t\t\toutput1_G = cv2.equalizeHist(G)\n",
        "\t\t\t\toutput1_B = cv2.equalizeHist(B)\n",
        "\t\t\t\timage = cv2.merge((output1_R, output1_G, output1_B))\n",
        "\n",
        "\t\timage = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\t\timages.append(image)\n",
        "\n",
        "\t\tX = np.array(images) / 255.0 #convierto de lista a numpy\n",
        "\t\ttest_X = X.astype('float32')\n",
        "\t\ttest_X = test_X / 255.\n",
        "\n",
        "\t\t#print(contador)\n",
        "\t\t#contador = contador + 1\n",
        "\t\tpredicted_classes = model.predict(test_X)\n",
        "\t\ttest_array = np.append(predicted_classes[0],imagePath)\n",
        "\t\ttest_array = np.append(test_array,label)\n",
        "\t\tif train_test == str(FOLD):\n",
        "\t\t\ttest_array = np.append(test_array,'test')\n",
        "\t\telse:\n",
        "\t\t\ttest_array = np.append(test_array,'train')\n",
        "\t\ttest_array = np.array(test_array);\n",
        "\t\tcsv_data.append(test_array)\n",
        "\n",
        "\n",
        "\tdf = pd.DataFrame(csv_data)\n",
        "\tprint('/content/drive/My Drive/test_data/fold_'+str(FOLD)+'/'+'/result_model_'+filter_types_applied_string+'.csv')\n",
        "\tif not os.path.exists('/content/drive/My Drive/test_data/fold_'+str(FOLD)+'/'):\n",
        "\t\tos.makedirs('/content/drive/My Drive/test_data/fold_'+str(FOLD)+'/')\n",
        "\t#df.to_csv('test_data/fold_'+str(FOLD)+'/'+'/result_model_filter_'+filter_types_applied_string+'.csv')\n",
        "\tdf.to_csv('/content/drive/My Drive/test_data/fold_'+str(FOLD)+'/'+'/result_model_'+filter_types_applied_string+'.csv')\n",
        "\tdel model\n",
        "\tgc.collect()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHsk8gwWh4OB"
      },
      "source": [
        "filter = [\"1\",\"2\",\"3\"]\n",
        "filter2 = [\"4\", \"5\",\"6\"]\n",
        "for x in filter2:\n",
        "    naive(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh8xNjEIsugk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3ccdab-7d6c-417e-c2e6-cead4fbd5dcd"
      },
      "source": [
        "naive(\"0\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading images...\n",
            "selected fold: 4\n",
            "\n",
            "Number of training samples: 1595 \n",
            "Number of testing samples: 587\n",
            "Class mappings are: ['covid' 'pneumonia' 'regular']\n",
            "Compiling VGG16...\n",
            "Compiling model...\n",
            "Model has 14747971 parameters\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_3 (Average (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 14,747,971\n",
            "Trainable params: 2,392,963\n",
            "Non-trainable params: 12,355,008\n",
            "_________________________________________________________________\n",
            "Model summary None\n",
            "Starting training model...\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 25s 478ms/step - loss: 0.8076 - accuracy: 0.6746\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 18s 356ms/step - loss: 0.5442 - accuracy: 0.8006\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 17s 346ms/step - loss: 0.4514 - accuracy: 0.8345\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 18s 356ms/step - loss: 0.3761 - accuracy: 0.8633\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 19s 371ms/step - loss: 0.3770 - accuracy: 0.8652\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 18s 361ms/step - loss: 0.3402 - accuracy: 0.8671\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 18s 366ms/step - loss: 0.3095 - accuracy: 0.8922\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 17s 341ms/step - loss: 0.2802 - accuracy: 0.9003\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 17s 339ms/step - loss: 0.2674 - accuracy: 0.9034\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 18s 364ms/step - loss: 0.2615 - accuracy: 0.9085\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 18s 356ms/step - loss: 0.2307 - accuracy: 0.9317\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 17s 344ms/step - loss: 0.2053 - accuracy: 0.9323\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 17s 342ms/step - loss: 0.2065 - accuracy: 0.9361\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 0.2090 - accuracy: 0.9292\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 17s 347ms/step - loss: 0.1908 - accuracy: 0.9361\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 17s 341ms/step - loss: 0.1863 - accuracy: 0.9442\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 18s 351ms/step - loss: 0.1940 - accuracy: 0.9411\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 19s 370ms/step - loss: 0.1924 - accuracy: 0.9392\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 17s 347ms/step - loss: 0.1774 - accuracy: 0.9511\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 17s 343ms/step - loss: 0.1589 - accuracy: 0.9555\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 18s 356ms/step - loss: 0.1662 - accuracy: 0.9480\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 18s 363ms/step - loss: 0.1591 - accuracy: 0.9492\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 17s 346ms/step - loss: 0.1492 - accuracy: 0.9517\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 17s 345ms/step - loss: 0.1482 - accuracy: 0.9567\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 0.1592 - accuracy: 0.9542\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 18s 357ms/step - loss: 0.1411 - accuracy: 0.9592\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 19s 371ms/step - loss: 0.1443 - accuracy: 0.9524\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 18s 351ms/step - loss: 0.1370 - accuracy: 0.9611\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 18s 350ms/step - loss: 0.1308 - accuracy: 0.9567\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 18s 355ms/step - loss: 0.1452 - accuracy: 0.9555\n",
            "Done\n",
            "/content/drive/My Drive/test_data/fold_4//result_model_0noFilter.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbuncwnCT61b",
        "outputId": "d4c99da5-a5f4-496f-8930-1fbe599add10"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}